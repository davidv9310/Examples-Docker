{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations read: 150\n"
     ]
    }
   ],
   "source": [
    "from daal.data_management import FileDataSource\n",
    "from daal.data_management import HomogenNumericTable\n",
    "from daal.data_management import DataSourceIface\n",
    "from daal.data_management import NumericTableIface\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataset_filename = 'iris.data'\n",
    "iris_datasource = FileDataSource(dataset_filename, DataSourceIface.doAllocateNumericTable, \n",
    "                                 DataSourceIface.doDictionaryFromContext)\n",
    "number_of_observations = iris_datasource.loadDataBlock()\n",
    "\n",
    "print(\"Observations read: {}\".format(number_of_observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is C Contiguous? False\n",
      "Is C Contiguous? True\n",
      "Observations read: 150\n"
     ]
    }
   ],
   "source": [
    "data_to_pandas = pd.read_csv('iris.data', delimiter=',', names=['sepal_length', 'sepal_width',\n",
    "                                                                'petal_length', 'petal_width', \n",
    "                                                                'class'])\n",
    "\n",
    "data_array = data_to_pandas.values\n",
    "numpy_array = data_to_pandas.transpose()[0: 4].transpose().values\n",
    "numpy_array_targets = data_to_pandas.transpose()[4: 5].transpose().values\n",
    "print(\"Is C Contiguous? {}\".format(numpy_array.flags['C']))\n",
    "\n",
    "# Important! To crate a HomogenNumericTable the array must be contiguous.\n",
    "numpy_array = np.ascontiguousarray(numpy_array, dtype=np.double)\n",
    "print(\"Is C Contiguous? {}\".format(numpy_array.flags['C']))\n",
    "\n",
    "array_nt = HomogenNumericTable(numpy_array)\n",
    "print(\"Observations read: {}\".format(array_nt.getNumberOfRows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is C Contiguous? False\n",
      "Is C Contiguous? True\n",
      "Observations read: 150\n"
     ]
    }
   ],
   "source": [
    "iris_targets = data_to_pandas.transpose()[4: 5].transpose()\n",
    "\n",
    "le_data = preprocessing.LabelEncoder()\n",
    "le_data.fit(iris_targets.values.ravel())\n",
    "iris_target_encoded = le_data.transform(iris_targets.values.ravel())\n",
    "iris_target_encoded.shape = (150, 1)\n",
    "\n",
    "data_array[:, :5] = iris_target_encoded\n",
    "data_array[:, :-1] = numpy_array\n",
    "\n",
    "print(\"Is C Contiguous? {}\".format(data_array.flags['C']))\n",
    "\n",
    "data_array = np.ascontiguousarray(data_array, dtype=np.double)\n",
    "print(\"Is C Contiguous? {}\".format(data_array.flags['C']))\n",
    "\n",
    "array_nt_data = HomogenNumericTable(data_array)\n",
    "print(\"Observations read: {}\".format(array_nt_data.getNumberOfRows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (150,4)\n",
      "Dimensions: (150,5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions: ({},{})\".format(array_nt.getNumberOfRows(), array_nt.getNumberOfColumns()))\n",
    "print(\"Dimensions: ({},{})\".format(array_nt_data.getNumberOfRows(), array_nt_data.getNumberOfColumns()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (150, 4)\n",
      "Dimensions: (150, 5)\n"
     ]
    }
   ],
   "source": [
    "from daal.data_management import BlockDescriptor_Float64, readOnly, HomogenNumericTable\n",
    "\n",
    "block_descriptor = BlockDescriptor_Float64()\n",
    "array_nt.getBlockOfRows(0, array_nt.getNumberOfRows(), readOnly, block_descriptor)\n",
    "numpy_array2 = block_descriptor.getArray()\n",
    "\n",
    "array_nt.releaseBlockOfRows(block_descriptor)\n",
    "print(\"Dimensions: {}\".format(numpy_array2.shape))\n",
    "\n",
    "block_descriptor_data = BlockDescriptor_Float64()\n",
    "array_nt_data.getBlockOfRows(0, array_nt_data.getNumberOfRows(), readOnly, block_descriptor_data)\n",
    "data_array2 = block_descriptor_data.getArray()\n",
    "\n",
    "array_nt_data.releaseBlockOfRows(block_descriptor_data)\n",
    "print(\"Dimensions: {}\".format(data_array2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5.006\n",
      "1    3.418\n",
      "2    1.464\n",
      "3    0.244\n",
      "4    0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "average_setosa = []\n",
    "average_versicolor = []\n",
    "average_virginica = []\n",
    "\n",
    "for row in data_array:\n",
    "    if row[4] == 0.0:\n",
    "        average_setosa.append(row)\n",
    "    elif row[4] == 1.0:\n",
    "        average_versicolor.append(row)\n",
    "    elif row[4] == 2.0:\n",
    "        average_virginica.append(row)\n",
    "    else: \n",
    "        continue\n",
    "\n",
    "\n",
    "datos_setosa = pd.DataFrame(average_setosa)\n",
    "datos_versicolor = pd.DataFrame(average_versicolor)\n",
    "datos_virginica = pd.DataFrame(average_virginica)\n",
    "\n",
    "mean_setosa = datos_setosa.mean()\n",
    "mean_versicolor = datos_versicolor.mean()\n",
    "mean_virginica = datos_virginica.mean()\n",
    "print(mean_setosa)\n",
    "# print(mean_versicolor)\n",
    "# print(mean_virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in Training Partition: 120\n",
      "Number of Observations in Test Partition: 30\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.choice(len(numpy_array), size=math.floor(.8*len(numpy_array)), replace=False)\n",
    "select = np.in1d(range(numpy_array.shape[0]), sample)\n",
    "\n",
    "numpy_train_data = numpy_array[select,:]\n",
    "numpy_test_data = numpy_array[~select,:]\n",
    "\n",
    "train_data_table = HomogenNumericTable(numpy_train_data)\n",
    "test_data_table = HomogenNumericTable(numpy_test_data)\n",
    "\n",
    "print(\"Number of Observations in Training Partition: {}\".format(train_data_table.getNumberOfRows()))\n",
    "print(\"Number of Observations in Test Partition: {}\".format(test_data_table.getNumberOfRows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in Training Partition: 120\n",
      "Number of Observations in Test Partition: 30\n"
     ]
    }
   ],
   "source": [
    "sample_data = np.random.choice(len(data_array), size=math.floor(.8*len(data_array)), replace=False)\n",
    "select_data = np.in1d(range(data_array.shape[0]), sample_data)\n",
    "\n",
    "numpy_train_data2 = data_array[select,:]\n",
    "numpy_test_data2 = data_array[~select,:]\n",
    "\n",
    "train_data_table2 = HomogenNumericTable(numpy_train_data2)\n",
    "test_data_table2 = HomogenNumericTable(numpy_test_data2)\n",
    "\n",
    "print(\"Number of Observations in Training Partition: {}\".format(train_data_table2.getNumberOfRows()))\n",
    "print(\"Number of Observations in Test Partition: {}\".format(test_data_table2.getNumberOfRows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the train_data dependent variable: (120, 1)\n",
      "Dimension of the train_data: (120, 2)\n",
      "Dimension of the test_data dependent variable: (30, 1)\n",
      "Dimension of the test_data: (30, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data_dependent_variable = numpy_train_data2[:, 4].reshape(120,1)\n",
    "print(\"Dimension of the train_data dependent variable: {}\".format(train_data_dependent_variable.shape))\n",
    "\n",
    "train_data = np.delete(numpy_train_data2, (0, 1, 4), axis=1)\n",
    "print(\"Dimension of the train_data: {}\".format(train_data.shape))\n",
    "\n",
    "# We need to do the same with the test_data\n",
    "\n",
    "test_data_dependent_variable = numpy_test_data2[:, 4].reshape(30,1)\n",
    "print(\"Dimension of the test_data dependent variable: {}\".format(test_data_dependent_variable.shape))\n",
    "\n",
    "test_data = np.delete(numpy_test_data2, (0, 1, 4), axis=1)\n",
    "print(\"Dimension of the test_data: {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is C Contiguous? True\n",
      "Is C Contiguous? True\n",
      "Coeficients: [[-0.445591    0.19662728  0.60697512]]\n"
     ]
    }
   ],
   "source": [
    "from daal.algorithms.linear_regression import training\n",
    "\n",
    "train_data = np.ascontiguousarray(train_data, dtype=np.double)\n",
    "print(\"Is C Contiguous? {}\".format(train_data.flags['C']))\n",
    "train_data_table = HomogenNumericTable(train_data)\n",
    "\n",
    "train_data_dependent_variable = np.ascontiguousarray(train_data_dependent_variable, dtype=np.double)\n",
    "print(\"Is C Contiguous? {}\".format(train_data_dependent_variable.flags['C']))\n",
    "train_outcome_table = HomogenNumericTable(train_data_dependent_variable)\n",
    "\n",
    "algorithm = training.Batch_Float64NormEqDense()\n",
    "algorithm.input.set(training.data, train_data_table)\n",
    "algorithm.input.set(training.dependentVariables, train_outcome_table)\n",
    "trainingResult = algorithm.compute()\n",
    "\n",
    "beta = trainingResult.get(training.model).getBeta()\n",
    "block_descriptor = BlockDescriptor_Float64()\n",
    "beta.getBlockOfRows(0, beta.getNumberOfRows(), readOnly, block_descriptor)\n",
    "beta_coeficients = block_descriptor.getArray()\n",
    "beta.releaseBlockOfRows(block_descriptor)\n",
    "\n",
    "print(\"Coeficients: {}\".format(beta_coeficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('Coeficients_Model.csv', beta_coeficients, delimiter=',')\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is C Contiguous? True\n",
      "Is C Contiguous? True\n",
      "First 4 predicted values:\n",
      "[[ 0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]]\n",
      "First 4 real responses:\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]]\n"
     ]
    }
   ],
   "source": [
    "from daal.algorithms.linear_regression import prediction\n",
    "\n",
    "# print(test_data)\n",
    "test_data = np.ascontiguousarray(test_data, dtype=np.double)\n",
    "print(\"Is C Contiguous? {}\".format(test_data.flags['C']))\n",
    "test_data_table = HomogenNumericTable(test_data)\n",
    "\n",
    "# print(test_data_dependent_variable)\n",
    "test_data_dependent_variable = np.ascontiguousarray(test_data_dependent_variable, dtype=np.double)\n",
    "print(\"Is C Contiguous? {}\".format(test_data_dependent_variable.flags['C']))\n",
    "test_outcome_table = HomogenNumericTable(test_data_dependent_variable)\n",
    "\n",
    "algorithm = prediction.Batch()\n",
    "algorithm.input.setTable(prediction.data, test_data_table)\n",
    "algorithm.input.setModel(prediction.model, trainingResult.get(training.model))\n",
    "\n",
    "predictionResult = algorithm.compute()\n",
    "\n",
    "test_result_data_table = predictionResult.get(prediction.prediction)\n",
    "\n",
    "block_descriptor = BlockDescriptor_Float64()\n",
    "\n",
    "test_result_data_table.getBlockOfRows(0, test_result_data_table.getNumberOfRows(), readOnly, block_descriptor)\n",
    "\n",
    "numpy_test_result = block_descriptor.getArray()\n",
    "\n",
    "test_result_data_table.releaseBlockOfRows(block_descriptor)\n",
    "\n",
    "prediction = numpy_test_result.round()\n",
    "\n",
    "print(\"First 4 predicted values:\")\n",
    "print(prediction[1:30])\n",
    "print(\"First 4 real responses:\")\n",
    "print(test_data_dependent_variable[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<daal.algorithms.linear_regression.Model; proxy of <Swig Object of type 'daal::services::SharedPtr< daal::algorithms::linear_regression::interface1::Model > *' at 0x000001F65DC5FCF0> >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingResult.get(training.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.24578076578697977\n"
     ]
    }
   ],
   "source": [
    "def RMSE(y, y_prime):\n",
    "    return np.sqrt(np.mean((y_prime - y)**2))\n",
    "\n",
    "print(\"RMSE: {}\".format(RMSE(test_data_dependent_variable, numpy_test_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 degree of expanstion RMSE: 0.24774700955233306\n",
      "2 degree of expanstion RMSE: 0.2414113578207227\n",
      "3 degree of expanstion RMSE: 0.2357479358554484\n",
      "4 degree of expanstion RMSE: 0.22881972899750544\n"
     ]
    }
   ],
   "source": [
    "from daal.algorithms.ridge_regression import training\n",
    "from daal.algorithms.ridge_regression import prediction\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "train_outcome_table = HomogenNumericTable(train_data_dependent_variable)\n",
    "\n",
    "for i in range(1,5):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "\n",
    "    expanded_train_data = poly.fit_transform(train_data)\n",
    "    train_data_table = HomogenNumericTable(expanded_train_data)    \n",
    "\n",
    "    algorithm = training.Batch()\n",
    "    algorithm.input.set(training.data, train_data_table)\n",
    "    algorithm.input.set(training.dependentVariables, train_outcome_table)\n",
    "\n",
    "    training_model = algorithm.compute().get(training.model)\n",
    "\n",
    "    expanded_test_data = poly.fit_transform(test_data)\n",
    "\n",
    "    test_data_table = HomogenNumericTable(expanded_test_data)\n",
    "    test_outcome_table = HomogenNumericTable(test_data_dependent_variable)\n",
    "\n",
    "    prediction_algorithm = prediction.Batch()\n",
    "\n",
    "    prediction_algorithm.input.setNumericTableInput(prediction.data, test_data_table)\n",
    "    prediction_algorithm.input.setModelInput(prediction.model, training_model)\n",
    "\n",
    "    prediction_result = prediction_algorithm.compute()\n",
    "\n",
    "    test_result_data_table = prediction_result.get(prediction.prediction)\n",
    "    block_descriptor = BlockDescriptor_Float64()\n",
    "    test_result_data_table.getBlockOfRows(0, test_result_data_table.getNumberOfRows(), \n",
    "                                              readOnly, block_descriptor)\n",
    "    numpy_test_result = block_descriptor.getArray()\n",
    "    test_result_data_table.releaseBlockOfRows(block_descriptor)\n",
    "\n",
    "    print(\"{} degree of expanstion RMSE: {}\".format(i, RMSE(test_data_dependent_variable,numpy_test_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 degree of expanstion RMSE: 0.9570483053328717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "for i in range(5,6):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    expanded_train_data = poly.fit_transform(train_data)\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    regr.fit(expanded_train_data, train_data_dependent_variable)\n",
    "\n",
    "    numpy_test_result = regr.predict(poly.fit_transform(test_data))\n",
    "    \n",
    "    print(\"{} degree of expanstion RMSE: {}\".format(i, RMSE(test_data_dependent_variable,numpy_test_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
